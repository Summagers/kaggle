{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 30) # 27 columns of data in training set\n",
    "\n",
    "# import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn import datasets, cross_validation, metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Imputer\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_features(data):    \n",
    "    '''\n",
    "    Extract date-time features from dataframe 'data'.\n",
    "    Converts date_time, srch_ci, and srch_co fields into\n",
    "    components (year, month, day, etc) and drops the \n",
    "    original field.\n",
    "    '''\n",
    "    extract_datetimes(data, 'date_time')\n",
    "    extract_datetimes(data, 'srch_ci')\n",
    "    extract_datetimes(data, 'srch_co')\n",
    "    \n",
    "    data = data.drop(['date_time', 'srch_ci', 'srch_co'], axis=1)\n",
    "    \n",
    "    has_null = ['orig_destination_distance', 'srch_ci_year', 'srch_ci_month', \n",
    "                'srch_ci_day', 'srch_ci_hour', 'srch_ci_minute', \n",
    "                'srch_ci_dayofyear', 'srch_ci_dayofweek', 'srch_co_year', \n",
    "                'srch_co_month', 'srch_co_day', 'srch_co_hour', 'srch_co_minute',\n",
    "                'srch_co_dayofyear', 'srch_co_dayofweek']\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0, copy=False)\n",
    "    data[has_null] = imp.fit_transform(data[has_null])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def extract_datetimes(data, field):\n",
    "    data[field] = pd.to_datetime(data[field],errors='coerce')\n",
    "    data[field+'_year'] = data[field].dt.year\n",
    "    data[field+'_month'] = data[field].dt.month\n",
    "    data[field+'_day'] = data[field].dt.day\n",
    "    data[field+'_hour'] = data[field].dt.hour\n",
    "    data[field+'_minute'] = data[field].dt.minute\n",
    "    data[field+'_dayofyear'] = data[field].dt.dayofyear\n",
    "    data[field+'_dayofweek'] = data[field].dt.dayofweek\n",
    "\n",
    "def make_PCA(X, n_comp):\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    pca.fit(X)\n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_PCA = True\n",
    "save_preds = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv('data/sample_submission.csv')\n",
    "train_data = make_features(pd.read_csv('data/train.csv', nrows=50000)) # 37,670,294 total lines\n",
    "test_data = make_features(pd.read_csv('data/test.csv'))   # 2,528,244 total lines\n",
    "destinations_data = pd.read_csv('data/destinations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_data['srch_destination_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# destinations_data[destinations_data['srch_destination_id']==train_data['srch_destination_id'][3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['site_name', 'posa_continent', 'user_location_country',\n",
    "       'user_location_region', 'user_location_city',\n",
    "       'orig_destination_distance', 'user_id', 'is_mobile', 'is_package',\n",
    "       'channel', 'srch_adults_cnt', 'srch_children_cnt', 'srch_rm_cnt',\n",
    "       'srch_destination_id', 'srch_destination_type_id',\n",
    "       'hotel_continent', 'hotel_country', 'hotel_market',\n",
    "       'date_time_year', 'date_time_month', 'date_time_day', 'date_time_hour',\n",
    "       'date_time_minute', 'date_time_dayofyear', 'date_time_dayofweek',\n",
    "       'srch_ci_year', 'srch_ci_month', 'srch_ci_day', 'srch_ci_hour',\n",
    "       'srch_ci_minute', 'srch_ci_dayofyear', 'srch_ci_dayofweek',\n",
    "       'srch_co_year', 'srch_co_month', 'srch_co_day', 'srch_co_hour',\n",
    "       'srch_co_minute', 'srch_co_dayofyear', 'srch_co_dayofweek']\n",
    "\n",
    "# 'srch_ci', 'srch_co', 'orig_destination_distance', 'is_booking', 'cnt',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = train_data.ix[:,features]\n",
    "y_all = train_data.ix[:,'hotel_cluster']\n",
    "X_test = test_data.ix[:,features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # checking correlation of features\n",
    "# plt.matshow(X_all.corr())\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if use_PCA:\n",
    "    X = X_all.as_matrix()\n",
    "    pca = make_PCA(X, 15)\n",
    "    X = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate training and cross-validation features\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y_all, train_size=.99, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train: Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expedia_rfc = RandomForestClassifier(n_estimators=100, \n",
    "                                     max_leaf_nodes=6, \n",
    "                                     criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time expedia_rfc = expedia_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "score_train = expedia_rfc.score(X_train, y_train)\n",
    "score_cv = expedia_rfc.score(X_cv, y_cv)\n",
    "\n",
    "# train/cv\n",
    "print ('Training Score:', score_train, ', CV Score:', score_cv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_importance = zip(features, expedia_rfc.feature_importances_)\n",
    "for x in sorted(feature_importance, key=lambda x: -x[1]):\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if use_PCA:\n",
    "    X_test = pca.transform(X_test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5594eae5325f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# break the test set into n = num_split sets to predict on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msplit_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnum_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mn_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtop_pred_hotel_cluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "# break the test set into n = num_split sets to predict on\n",
    "split_size = int(X_test.shape[0]*.1)\n",
    "num_splits = 10\n",
    "n_test = X_test.shape[0]\n",
    "top_pred_hotel_cluster = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(num_splits):\n",
    "    prob_prediction = expedia_rfc.predict_proba(X_test[int(i*n_test/num_splits):int((i+1)*n_test/num_splits)])\n",
    "    top_pred_hotel_cluster.append([' '.join([str(hotel) for hotel in row]) for row in np.argsort(prob_prediction)[:,-5:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "prob_prediction = expedia_rfc.predict_proba(X_test[:split_size])\n",
    "top_pred_hotel_cluster.append([' '.join([str(hotel) for hotel in row]) for row in np.argsort(prob_prediction)[:,-5:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array(top_pred_hotel_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(np.concatenate((a[0],a[1],a[2],a[3],a[4],a[5],a[6],a[7],a[8],a[9]), axis=0), columns=['hotel_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('expedia-rf-2016-04-23-s1.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
