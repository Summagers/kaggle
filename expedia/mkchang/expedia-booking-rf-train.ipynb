{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expedia Hotel Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.max_columns', 30) # 27 columns of data in training set\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_features(data, destinations_data):    \n",
    "    '''\n",
    "    Extract date-time features from dataframe 'data'.\n",
    "    Converts date_time, srch_ci, and srch_co fields  (if they exist) \n",
    "    into components (year, month, day, etc) and drops the original field.\n",
    "    '''\n",
    "    \n",
    "    # Extract date-time features\n",
    "    fields = ['date_time', 'srch_ci', 'srch_co']\n",
    "    for field in fields:\n",
    "        if field in data.keys():\n",
    "            extract_datetimes(data, field)\n",
    "            data = data.drop(field, axis=1)\n",
    "    \n",
    "    \n",
    "    # merge in srch_destination_id d1-d149 fields\n",
    "    data = pd.merge(data, destinations_data, on='srch_destination_id', how='left')\n",
    "\n",
    "    # Check for nulls\n",
    "    null_bool = data.isnull().sum()\n",
    "    if null_bool.sum()>0:\n",
    "        # Only impute columns with nulls\n",
    "        has_null = data.columns[null_bool>0]\n",
    "\n",
    "        imp = Imputer(missing_values='NaN', strategy='mean', axis=0, copy=False)\n",
    "        data[has_null] = imp.fit_transform(data[has_null])\n",
    "    return data\n",
    "\n",
    "def extract_datetimes(data, field):\n",
    "    data[field] = pd.to_datetime(data[field],errors='coerce')\n",
    "    data[field+'_year'] = data[field].dt.year\n",
    "#     data[field+'_month'] = data[field].dt.month\n",
    "#     data[field+'_day'] = data[field].dt.day\n",
    "#     data[field+'_hour'] = data[field].dt.hour\n",
    "#     data[field+'_minute'] = data[field].dt.minute\n",
    "    data[field+'_dayofyear'] = data[field].dt.dayofyear\n",
    "    data[field+'_dayofweek'] = data[field].dt.dayofweek\n",
    "\n",
    "def make_PCA(X, n_comp):\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    pca.fit(X)\n",
    "    return pca\n",
    "\n",
    "def apk(actual, predicted, k=5):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=5):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])\n",
    "\n",
    "def mapk_score(X, y, estimator, num_splits=10):\n",
    "# Score MAP@5 for X using estimator against target y, \n",
    "# splits into num_splits sets to reduce memory requirement\n",
    "\n",
    "    n_test = X.shape[0]\n",
    "    top_pred_hotel_cluster = []\n",
    "\n",
    "    for i in range(num_splits):ï¿¼\n",
    "        prob_prediction = estimator.predict_proba(X_train[int(i*n_test/num_splits):int((i+1)*n_test/num_splits)])\n",
    "        top_pred_hotel_cluster.extend((np.argsort(prob_prediction)[:,-5:]).tolist())\n",
    "\n",
    "    return mapk([[i] for i in y.values.tolist()], top_pred_hotel_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_PCA = False\n",
    "save_preds = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train: Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['site_name', 'posa_continent', 'user_location_country',\n",
    "       'user_location_region', 'user_location_city',\n",
    "       'orig_destination_distance', 'user_id', 'is_mobile', 'is_package',\n",
    "       'channel', 'srch_ci', 'srch_co', 'srch_adults_cnt', 'srch_children_cnt',\n",
    "       'srch_rm_cnt', 'srch_destination_id', 'srch_destination_type_id',\n",
    "       'is_booking', 'cnt', 'hotel_country', 'hotel_market', 'hotel_continent',\n",
    "       'hotel_cluster']\n",
    "# 'date_time', \n",
    "\n",
    "cols_test = cols[:17]\n",
    "cols_test.extend(cols[19:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "destinations_data = pd.read_csv('data/destinations.csv')\n",
    "\n",
    "chunksize = 380000\n",
    "chunk_train = pd.read_csv('data/train.csv', usecols=cols, chunksize=chunksize, iterator=True)\n",
    "chunk_test = pd.read_csv('data/test.csv', usecols=cols_test, chunksize=chunksize, iterator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull a row for headers\n",
    "test_data = make_features(chunk_test.get_chunk(1), destinations_data)  # 2,528,244 total lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators = 50\n",
    "expedia_rfc = RandomForestClassifier(n_estimators=n_estimators, max_leaf_nodes=10, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "for i in range(1,100):\n",
    "    train_data = make_features(chunk_train.get_chunk(chunksize), destinations_data) # 37,670,294 total lines\n",
    "\n",
    "    # Take features from columns in test data, ignoring some fields uniquely in train\n",
    "    features = test_data.columns.tolist()[1:]\n",
    "\n",
    "    X_all = train_data.ix[:,features]\n",
    "    y_all = train_data.ix[:,'hotel_cluster']\n",
    "\n",
    "    if use_PCA:\n",
    "        X = X_all.as_matrix()\n",
    "        pca = make_PCA(X, 50)\n",
    "        X = pca.transform(X)\n",
    "    else:\n",
    "        X = X_all   \n",
    "\n",
    "    # Generate training and cross-validation features\n",
    "    X_train, X_cv, y_train, y_cv = train_test_split(X, y_all, train_size=.8, random_state=1)\n",
    "\n",
    "    # Add more estimators\n",
    "    expedia_rfc.set_params(n_estimators=i*n_estimators, warm_start=True) \n",
    "    \n",
    "    # Fit the model\n",
    "    expedia_rfc = expedia_rfc.fit(X_train, y_train)\n",
    "\n",
    "    # Cross-validate the model\n",
    "    num_splits=int(chunksize/1000)\n",
    "\n",
    "    score_train = mapk_score(X_train, y_train, expedia_rfc, num_splits=num_splits)\n",
    "    score_cv = mapk_score(X_cv, y_cv, expedia_rfc, num_splits=num_splits)\n",
    "\n",
    "    print ('Iteration:', i, ' Training Score:', score_train, ' CV Score:', score_cv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_importance = zip(features, expedia_rfc.feature_importances_)\n",
    "for x in sorted(feature_importance, key=lambda x: -x[1]):\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(expedia_rfc, 'model/expedia_rfc.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expedia_rfc = joblib.load('model/expedia_rfc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if use_PCA:\n",
    "    X_test = pca.transform(X_test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pull a row for headers\n",
    "test_data = make_features(chunk_test.get_chunk(1000000), destinations_data)  # 2,528,244 total lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test_data.ix[:,features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# break the test set into n = num_split sets to predict on\n",
    "num_splits = 10\n",
    "n_test = X_test.shape[0]\n",
    "top_pred_hotel_cluster = []\n",
    "\n",
    "for i in range(num_splits):\n",
    "    prob_prediction = expedia_rfc.predict_proba(X_test[int(i*n_test/num_splits):int((i+1)*n_test/num_splits)])\n",
    "    top_pred_hotel_cluster.extend([' '.join([str(hotel) for hotel in row]) for row in np.argsort(prob_prediction)[:,-5:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(top_pred_hotel_cluster, columns=['hotel_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if submission.shape[0] == 2528243:\n",
    "    submission.to_csv('expedia-rf-2016-05-01-s1.csv', index_label='Id')\n",
    "else:\n",
    "    print('submission size does not match correct value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
